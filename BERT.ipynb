{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ea5b803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @author: Jayanta Banik, Ankit Gupta\n",
    "# @tag: DarkSourceOfCode, halfdevilx333\n",
    "# @afil: UCR grad student, UCR grad Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9ad7e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mux_selector using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d92ee94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-25 04:55:42.024065: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-25 04:55:47.274662: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-25 04:55:47.275085: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-25 04:55:47.275110: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_text as text\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from official.nlp import optimization\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import DownloadMode\n",
    "from promptsource.templates import DatasetTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aea363e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment logger\n",
    "name = \"exp-000\"\n",
    "log_dir = \"experiments\"\n",
    "#logger = SummaryWriter(log_dir=osp.join(log_dir, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c040b06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-25 04:55:59.879182: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-03-25 04:55:59.879244: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "tf.get_logger().setLevel('ERROR')\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b30055b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1'\n",
    "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd2ca091",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 64\n",
    "init_lr = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b1a54f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"task.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20fa76b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e9cad6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df.w_task_set = le.fit_transform(df.w_task_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8757c4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.convert_to_tensor(df.input_text.values)\n",
    "y = tf.one_hot(df.w_task_set, depth=len(le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9f9479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples, num_classes = y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce625b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_memory_ds = {\n",
    "    'answer' : y, \n",
    "    'question' : X \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d0a247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bert_preprocess_model(sentence_features=['question'], seq_length=128):\n",
    "\n",
    "    input_segments = [\n",
    "        tf.keras.layers.Input(shape=(), dtype=tf.string, name=ft)\n",
    "        for ft in sentence_features]\n",
    "\n",
    "    bert_preprocess = hub.load(tfhub_handle_preprocess)\n",
    "    tokenizer = hub.KerasLayer(bert_preprocess.tokenize, name='tokenizer')\n",
    "    segments = [tokenizer(s) for s in input_segments]\n",
    "\n",
    "    truncated_segments = segments\n",
    "\n",
    "    packer = hub.KerasLayer(bert_preprocess.bert_pack_inputs,\n",
    "                          arguments=dict(seq_length=seq_length),\n",
    "                          name='packer')\n",
    "    model_inputs = packer(truncated_segments)\n",
    "    return tf.keras.Model(input_segments, model_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7242d92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model(num_classes):\n",
    "\n",
    "    class Classifier(tf.keras.Model):\n",
    "        def __init__(self, num_classes):\n",
    "            super(Classifier, self).__init__(name=\"prediction\")\n",
    "            self.encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True)\n",
    "            self.dropout = tf.keras.layers.Dropout(0.1)\n",
    "            self.dense = tf.keras.layers.Dense(num_classes)\n",
    "\n",
    "        def call(self, preprocessed_text):\n",
    "            encoder_outputs = self.encoder(preprocessed_text)\n",
    "            pooled_output = encoder_outputs[\"pooled_output\"]\n",
    "            x = self.dropout(pooled_output)\n",
    "            x = self.dense(x)\n",
    "            return x\n",
    "\n",
    "    model = Classifier(num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6921f8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_configuration():\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "#     metrics = tfa.metrics.MatthewsCorrelationCoefficient(num_classes=4) \n",
    "    # metrics = tf.metrics.Accuracy()\n",
    "    metrics = tf.keras.metrics.CategoricalAccuracy('accuracy', dtype=tf.float32)\n",
    "    return metrics, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43e51193",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocess_model = make_bert_preprocess_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acf40a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_from_tfds(in_memory_ds,  \n",
    "                           batch_size,\n",
    "                           bert_preprocess_model,\n",
    "                           target='question'):\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(in_memory_ds)\n",
    "  \n",
    "    num_examples = in_memory_ds[target].shape[0]\n",
    "\n",
    "    dataset = dataset.shuffle(num_examples)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    dataset = dataset.map(lambda ex: (bert_preprocess_model(ex['question']), ex['answer']))\n",
    "    \n",
    "    dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    return dataset, num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "078f15fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "\n",
    "    # metric have to be created inside the strategy scope\n",
    "    metrics, loss = get_configuration()\n",
    "\n",
    "    train_dataset, train_data_size = load_dataset_from_tfds(in_memory_ds,\n",
    "                                                          batch_size, \n",
    "                                                          bert_preprocess_model,\n",
    "                                                          target='answer')\n",
    "    steps_per_epoch = train_data_size // batch_size\n",
    "    num_train_steps = steps_per_epoch * epochs\n",
    "    num_warmup_steps = num_train_steps // 10\n",
    "\n",
    "    validation_dataset, validation_data_size = load_dataset_from_tfds(in_memory_ds,\n",
    "                                                                    batch_size,\n",
    "                                                                    bert_preprocess_model, \n",
    "                                                                    target='answer')\n",
    "    validation_steps = validation_data_size // batch_size\n",
    "\n",
    "    classifier_model = build_classifier_model(num_classes)\n",
    "\n",
    "    optimizer = optimization.create_optimizer(\n",
    "      init_lr=init_lr,\n",
    "      num_train_steps=num_train_steps,\n",
    "      num_warmup_steps=num_warmup_steps,\n",
    "      optimizer_type='adamw')\n",
    "\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    classifier_model.compile(optimizer=optimizer, loss=loss, metrics=[metrics])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47a86496",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfds_name = 'boolq'\n",
    "sentence_features = ['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2780036",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_save_path = 'my_models'\n",
    "bert_type = tfhub_handle_encoder.split('/')[-2]\n",
    "saved_model_name = f'{tfds_name.replace(\"/\", \"_\")}_{bert_type}'\n",
    "\n",
    "saved_model_path = os.path.join(main_save_path, saved_model_name)\n",
    "\n",
    "preprocess_inputs = bert_preprocess_model.inputs\n",
    "bert_encoder_inputs = bert_preprocess_model(preprocess_inputs)\n",
    "bert_outputs = classifier_model(bert_encoder_inputs)\n",
    "model_for_export = tf.keras.Model(preprocess_inputs, bert_outputs)\n",
    "\n",
    "# with tf.device('/job:localhost'):\n",
    "reloaded_model = tf.saved_model.load(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04852631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(record):\n",
    "    model_inputs = [[record[ft]] for ft in sentence_features]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f65a8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_serving(record):\n",
    "    model_inputs = {ft: record[ft] for ft in sentence_features}\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1105886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_bert_results(test, bert_result, dataset_name):\n",
    "\n",
    "    bert_result_class = tf.argmax(bert_result, axis=1)[0]\n",
    "    print('sentence:', test[0].numpy())\n",
    "    \n",
    "    print('BERT results:', le.classes_[bert_result_class])\n",
    "\n",
    "    print('BERT raw results:', bert_result[0])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ffb352dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(s):\n",
    "    \n",
    "    s = tf.convert_to_tensor([s.encode('utf-8')], dtype='string', name='question')\n",
    "    result = reloaded_model(s)\n",
    "    bert_result_class = tf.argmax(result, axis=1)[0]\n",
    "    return le.classes_[bert_result_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bf14891b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BoolQ'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict('True or False? Sun rises from east?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
