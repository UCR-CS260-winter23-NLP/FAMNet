{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bbwl6E1E205R",
    "outputId": "7ab0c99b-8f25-4f48-a74b-ba54bf93c6bf"
   },
   "outputs": [],
   "source": [
    "# !pip install sentencepiece\n",
    "# !pip install transformers\n",
    "# !pip install rich[jupyter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate_template_de_en = lambda x:  \"Translate '%s' from german to english\"%x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "y6nEben93JAk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wmt16 (/home/agupt135/.cache/huggingface/datasets/wmt16/de-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227)\n",
      "100%|██████████████████| 7000/7000 [00:00<00:00, 11489.84it/s]\n",
      "100%|██████████████████| 7000/7000 [00:00<00:00, 11609.14it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "# df = pd.read_csv(\"https://raw.githubusercontent.com/Shivanandroy/T5-Finetuning-PyTorch/main/data/news_summary.csv\")\n",
    "# WMT16 dataset\n",
    "from datasets import load_dataset, DownloadMode, load_metric\n",
    "\n",
    "train_df = load_dataset(\"wmt16\", \"de-en\", split=\"train[:7000]\", num_proc=8)\n",
    "# eval_df = load_dataset(\"wmt16\", \"de-en\", split=\"validation\")\n",
    "\n",
    "# Create data frame\n",
    "df = pd.DataFrame({\n",
    "    \"source_text\":[i['translation']['en'] for i in tqdm(train_df)],\n",
    "    \"target_text\":[i['translation']['de'] for i in tqdm(train_df)]\n",
    "}).applymap(str)\n",
    "\n",
    "# eval_df_ds = pd.DataFrame({\n",
    "#     \"source_text\":[i['translation']['en'] for i in eval_df],\n",
    "#     \"target_text\":[i['translation']['de'] for i in eval_df]\n",
    "# })\n",
    "# eval_df_ds = eval_df_ds.applymap(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"de_en_translation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "Suxgy7wC4IqL",
    "outputId": "5725be18-918f-4fad-c6f4-587fd50899af"
   },
   "outputs": [],
   "source": [
    "# df = train_df_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.read_csv(\"de_en_translation.csv\")\n",
    "# df = df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "81f4PKa1F6aM",
    "outputId": "fcf57854-d194-4670-c783-35da1574ec5c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Resumption of the session</td>\n",
       "      <td>Wiederaufnahme der Sitzungsperiode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I declare resumed the session of the European ...</td>\n",
       "      <td>Ich erkläre die am Freitag, dem 17. Dezember u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Although, as you will have seen, the dreaded '...</td>\n",
       "      <td>Wie Sie feststellen konnten, ist der gefürchte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You have requested a debate on this subject in...</td>\n",
       "      <td>Im Parlament besteht der Wunsch nach einer Aus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the meantime, I should like to observe a mi...</td>\n",
       "      <td>Heute möchte ich Sie bitten - das ist auch der...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         source_text  \\\n",
       "0                          Resumption of the session   \n",
       "1  I declare resumed the session of the European ...   \n",
       "2  Although, as you will have seen, the dreaded '...   \n",
       "3  You have requested a debate on this subject in...   \n",
       "4  In the meantime, I should like to observe a mi...   \n",
       "\n",
       "                                         target_text  \n",
       "0                 Wiederaufnahme der Sitzungsperiode  \n",
       "1  Ich erkläre die am Freitag, dem 17. Dezember u...  \n",
       "2  Wie Sie feststellen konnten, ist der gefürchte...  \n",
       "3  Im Parlament besteht der Wunsch nach einer Aus...  \n",
       "4  Heute möchte ich Sie bitten - das ist auch der...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumption of the session \n",
      " Wiederaufnahme der Sitzungsperiode \n",
      " I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period. \n",
      " Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.\n"
     ]
    }
   ],
   "source": [
    "print(df.get(\"source_text\")[0],\"\\n\",df.get(\"target_text\")[0],\"\\n\",df.get(\"source_text\")[1],\"\\n\",df.get(\"target_text\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "wB441x104K-o"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-25 07:31:09.436413: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-25 07:31:09.436635: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-25 07:31:09.436659: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import os\n",
    "import gc\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "\n",
    "# Importing the T5 modules from huggingface/transformers\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, pipeline\n",
    "\n",
    "from rich.table import Column, Table\n",
    "from rich import box\n",
    "from rich.console import Console\n",
    "\n",
    "# define a rich console logger\n",
    "console=Console(record=True)\n",
    "\n",
    "def display_df(df):\n",
    "  \"\"\"display dataframe in ASCII format\"\"\"\n",
    "\n",
    "  console=Console()\n",
    "  table = Table(Column(\"input_text\", justify=\"center\" ), Column(\"source_text\", justify=\"center\"), title=\"Translation Data\",pad_edge=False, box=box.ASCII)\n",
    "\n",
    "  for i, row in enumerate(df.values.tolist()):\n",
    "    table.add_row(row[0], row[1])\n",
    "\n",
    "  console.print(table)\n",
    "\n",
    "training_logger = Table(Column(\"Epoch\", justify=\"center\" ), \n",
    "                        Column(\"Steps\", justify=\"center\"),\n",
    "                        Column(\"Loss\", justify=\"center\"), \n",
    "                        title=\"Training Status\",pad_edge=False, box=box.ASCII)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "tlYaKW9h4ai_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device :  cuda\n"
     ]
    }
   ],
   "source": [
    "# Setting up the device for GPU usage\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(\"device : \",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "8vLQPGAn4v17"
   },
   "outputs": [],
   "source": [
    "class YourDataSetClass(Dataset):\n",
    "  \"\"\"\n",
    "  Creating a custom dataset for reading the dataset and \n",
    "  loading it into the dataloader to pass it to the neural network for finetuning the model\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, dataframe, tokenizer, source_len, target_len, source_text, target_text):\n",
    "    self.tokenizer = tokenizer\n",
    "    self.data = dataframe\n",
    "    self.source_len = source_len\n",
    "    self.summ_len = target_len\n",
    "    self.target_text = self.data[target_text]\n",
    "    self.source_text = self.data[source_text]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.target_text)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    source_text = str(self.source_text[index])\n",
    "    target_text = str(self.target_text[index])\n",
    "\n",
    "    #cleaning data so as to ensure data is in string type\n",
    "    source_text = ' '.join(source_text.split())\n",
    "    target_text = ' '.join(target_text.split())\n",
    "\n",
    "    source = self.tokenizer.batch_encode_plus([source_text], max_length= self.source_len, pad_to_max_length=True, truncation=True, padding=\"max_length\", return_tensors='pt')\n",
    "    target = self.tokenizer.batch_encode_plus([target_text], max_length= self.summ_len, pad_to_max_length=True, truncation=True, padding=\"max_length\", return_tensors='pt')\n",
    "\n",
    "    source_ids = source['input_ids'].squeeze()\n",
    "    source_mask = source['attention_mask'].squeeze()\n",
    "    target_ids = target['input_ids'].squeeze()\n",
    "    target_mask = target['attention_mask'].squeeze()\n",
    "\n",
    "    return {\n",
    "        'source_ids': source_ids.to(dtype=torch.long), \n",
    "        'source_mask': source_mask.to(dtype=torch.long), \n",
    "        'target_ids': target_ids.to(dtype=torch.long),\n",
    "        'target_ids_y': target_ids.to(dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Nkj6wIMt40RK"
   },
   "outputs": [],
   "source": [
    "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
    "\n",
    "  \"\"\"\n",
    "  Function to be called for training with the parameters passed from main function\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  model.train()\n",
    "  for _,data in tqdm(enumerate(loader, 0)):\n",
    "    y = data['target_ids'].to(device, dtype = torch.long)\n",
    "    y_ids = y[:, :-1].contiguous()\n",
    "    lm_labels = y[:, 1:].clone().detach()\n",
    "    lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "    ids = data['source_ids'].to(device, dtype = torch.long)\n",
    "    mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=lm_labels)\n",
    "    loss = outputs[0]\n",
    "\n",
    "    if _%10==0:\n",
    "      training_logger.add_row(str(epoch), str(_), str(loss))\n",
    "      console.print(training_logger)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    torch.cuda.empty_cache()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "GUBykK-A43DF"
   },
   "outputs": [],
   "source": [
    "def validate(epoch, tokenizer, model, device, loader):\n",
    "\n",
    "  \"\"\"\n",
    "  Function to evaluate model for predictions\n",
    "\n",
    "  \"\"\"\n",
    "  model.eval()\n",
    "  predictions = []\n",
    "  actuals = []\n",
    "  with torch.no_grad():\n",
    "      for _, data in tqdm(enumerate(loader, 0)):\n",
    "          y = data['target_ids'].to(device, dtype = torch.long)\n",
    "          ids = data['source_ids'].to(device, dtype = torch.long)\n",
    "          mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "          generated_ids = model.generate(\n",
    "              input_ids = ids,\n",
    "              attention_mask = mask, \n",
    "              max_length=150, \n",
    "              num_beams=2,\n",
    "              repetition_penalty=2.5, \n",
    "              length_penalty=1.0, \n",
    "              early_stopping=True\n",
    "              )\n",
    "          preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "          target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
    "          if _%10==0:\n",
    "              console.print(f'Completed {_}')\n",
    "\n",
    "          predictions.extend(preds)\n",
    "          actuals.extend(target)\n",
    "  return predictions, actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Tw4RW_qO4_8T"
   },
   "outputs": [],
   "source": [
    "def T5Trainer(dataframe, source_text, target_text, model_params, output_dir=\"./outputs/en-de-translation/\" ):\n",
    "  \n",
    "  \"\"\"\n",
    "  T5 trainer\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  # Set random seeds and deterministic pytorch for reproducibility\n",
    "  torch.manual_seed(model_params[\"SEED\"]) # pytorch random seed\n",
    "  np.random.seed(model_params[\"SEED\"]) # numpy random seed\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "\n",
    "  # logging\n",
    "  console.log(f\"\"\"[Model]: Loading {model_params[\"MODEL\"]}...\\n\"\"\")\n",
    "\n",
    "  # tokenzier for encoding the text\n",
    "  tokenizer = T5Tokenizer.from_pretrained(model_params[\"MODEL\"])\n",
    "\n",
    "  # Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary. \n",
    "  # Further this model is sent to device (GPU/TPU) for using the hardware.\n",
    "  gc.collect()\n",
    "  model = T5ForConditionalGeneration.from_pretrained(model_params[\"MODEL\"])\n",
    "  model = model.to(device)\n",
    "  \n",
    "  # logging\n",
    "  console.log(f\"[Data]: Reading data...\\n\")\n",
    "\n",
    "  # Importing the raw dataset\n",
    "  dataframe = dataframe[[source_text,target_text]]\n",
    "  display_df(dataframe.head(2))\n",
    "\n",
    "  \n",
    "  # Creation of Dataset and Dataloader\n",
    "  # Defining the train size. So 80% of the data will be used for training and the rest for validation. \n",
    "  train_size = 0.8\n",
    "  train_dataset=dataframe.sample(frac=train_size,random_state = model_params[\"SEED\"])\n",
    "  val_dataset=dataframe.drop(train_dataset.index).reset_index(drop=True)\n",
    "  train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "  console.print(f\"FULL Dataset: {dataframe.shape}\")\n",
    "  console.print(f\"TRAIN Dataset: {train_dataset.shape}\")\n",
    "  console.print(f\"TEST Dataset: {val_dataset.shape}\\n\")\n",
    "\n",
    "\n",
    "  # Creating the Training and Validation dataset for further creation of Dataloader\n",
    "  training_set = YourDataSetClass(train_dataset, tokenizer, model_params[\"MAX_SOURCE_TEXT_LENGTH\"], model_params[\"MAX_TARGET_TEXT_LENGTH\"], source_text, target_text)\n",
    "  val_set = YourDataSetClass(val_dataset, tokenizer, model_params[\"MAX_SOURCE_TEXT_LENGTH\"], model_params[\"MAX_TARGET_TEXT_LENGTH\"], source_text, target_text)\n",
    "\n",
    "\n",
    "  # Defining the parameters for creation of dataloaders\n",
    "  train_params = {\n",
    "      'batch_size': model_params[\"TRAIN_BATCH_SIZE\"],\n",
    "      'shuffle': True,\n",
    "      'num_workers': 0\n",
    "      }\n",
    "\n",
    "\n",
    "  val_params = {\n",
    "      'batch_size': model_params[\"VALID_BATCH_SIZE\"],\n",
    "      'shuffle': False,\n",
    "      'num_workers': 0\n",
    "      }\n",
    "\n",
    "\n",
    "  # Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
    "  training_loader = DataLoader(training_set, **train_params)\n",
    "  val_loader = DataLoader(val_set, **val_params)\n",
    "\n",
    "\n",
    "  # Defining the optimizer that will be used to tune the weights of the network in the training session. \n",
    "  optimizer = torch.optim.Adam(params =  model.parameters(), lr=model_params[\"LEARNING_RATE\"])\n",
    "\n",
    "\n",
    "  # Training loop\n",
    "  console.log(f'[Initiating Fine Tuning]...\\n')\n",
    "\n",
    "  for epoch in tqdm(range(model_params[\"TRAIN_EPOCHS\"])):\n",
    "    train(epoch, tokenizer, model, device, training_loader, optimizer)\n",
    "      \n",
    "  console.log(f\"[Saving Model]...\\n\")\n",
    "  #Saving the model after training\n",
    "  path = os.path.join(output_dir, \"model_files\")\n",
    "  model.save_pretrained(path)\n",
    "  tokenizer.save_pretrained(path)\n",
    "\n",
    "\n",
    "  # evaluating test dataset\n",
    "  console.log(f\"[Initiating Validation]...\\n\")\n",
    "  for epoch in tqdm(range(model_params[\"VAL_EPOCHS\"])):\n",
    "    predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n",
    "    final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n",
    "    final_df.to_csv(os.path.join(output_dir,'predictions.csv'))\n",
    "  \n",
    "  console.save_text(os.path.join(output_dir,'logs.txt'))\n",
    "  \n",
    "  console.log(f\"[Validation Completed.]\\n\")\n",
    "  console.print(f\"\"\"[Model] Model saved @ {os.path.join(output_dir, \"model_files\")}\\n\"\"\")\n",
    "  console.print(f\"\"\"[Validation] Generation on Validation data saved @ {os.path.join(output_dir,'predictions.csv')}\\n\"\"\")\n",
    "  console.print(f\"\"\"[Logs] Logs saved @ {os.path.join(output_dir,'logs.txt')}\\n\"\"\")\n",
    "  text = 'Resumption of the session'\n",
    "  inference(trained_model=model, trained_tokenizer=tokenizer, text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "PxCpQwD8PDIs"
   },
   "outputs": [],
   "source": [
    "model_params={\n",
    "    \"MODEL\":\"t5-small\",             # model_type: t5-base/t5-large\n",
    "    \"TRAIN_BATCH_SIZE\":64,          # training batch size\n",
    "    \"VALID_BATCH_SIZE\":64,          # validation batch size\n",
    "    \"TRAIN_EPOCHS\":4,              # number of training epochs\n",
    "    \"VAL_EPOCHS\":5,                # number of validation epochs\n",
    "    \"LEARNING_RATE\":1e-4,          # learning rate\n",
    "    \"MAX_SOURCE_TEXT_LENGTH\":120,  # max length of source text\n",
    "    \"MAX_TARGET_TEXT_LENGTH\":120,   # max length of target text\n",
    "    \"SEED\": 42,                     # set seed for reproducibility \n",
    "    \"requires_grad\":True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(trained_model, trained_tokenizer, text):\n",
    "    generator = pipeline(\n",
    "        \"text2text-generation\",\n",
    "        model=trained_model,\n",
    "        tokenizer=trained_tokenizer,\n",
    "        device=0 if torch.cuda.is_available() else -1, # use GPU if available\n",
    "    )\n",
    "\n",
    "    input_text = text # input text for generation\n",
    "    generated_text = generator(input_text, max_length=50)\n",
    "    print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qijZoYeI55fM",
    "outputId": "69c68bb6-4fba-47e4-9e74-73f2579aa3c8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[07:31:14] </span><span style=\"font-weight: bold\">[</span>Model<span style=\"font-weight: bold\">]</span>: Loading t5-small<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                             <a href=\"file:///tmp/ipykernel_27241/405145780.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">405145780.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_27241/405145780.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[07:31:14]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mModel\u001b[1m]\u001b[0m: Loading t5-small\u001b[33m...\u001b[0m                                                             \u001b]8;id=812680;file:///tmp/ipykernel_27241/405145780.py\u001b\\\u001b[2m405145780.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=814158;file:///tmp/ipykernel_27241/405145780.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                                                                         \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agupt135/anaconda3/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[07:31:20] </span><span style=\"font-weight: bold\">[</span>Data<span style=\"font-weight: bold\">]</span>: Reading data<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                  <a href=\"file:///tmp/ipykernel_27241/405145780.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">405145780.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_27241/405145780.py#26\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">26</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[07:31:20]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mData\u001b[1m]\u001b[0m: Reading data\u001b[33m...\u001b[0m                                                                  \u001b]8;id=219950;file:///tmp/ipykernel_27241/405145780.py\u001b\\\u001b[2m405145780.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=570393;file:///tmp/ipykernel_27241/405145780.py#26\u001b\\\u001b[2m26\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                                                                         \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                 Translation Data                                                  </span>\n",
       "+-----------------------------------------------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">                      input_text                        </span>|<span style=\"font-weight: bold\">                       source_text                      </span>|\n",
       "|--------------------------------------------------------+--------------------------------------------------------|\n",
       "|               Resumption of the session                |           Wiederaufnahme der Sitzungsperiode           |\n",
       "|     I declare resumed the session of the European      |      Ich erkläre die am Freitag, dem 17. Dezember      |\n",
       "|Parliament adjourned on Friday 17 December 1999, and I  |     unterbrochene Sitzungsperiode des Europäischen     |\n",
       "| would like once again to wish you a happy new year in  |     Parlaments für wiederaufgenommen, wünsche Ihnen    |\n",
       "| the hope that you enjoyed a pleasant festive period.   |  nochmals alles Gute zum Jahreswechsel und hoffe, daß  |\n",
       "|                                                        |                Sie schöne Ferien hatten.               |\n",
       "+-----------------------------------------------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                 Translation Data                                                  \u001b[0m\n",
       "+-----------------------------------------------------------------------------------------------------------------+\n",
       "|\u001b[1m                      input_text                       \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                      source_text                      \u001b[0m|\n",
       "|--------------------------------------------------------+--------------------------------------------------------|\n",
       "|               Resumption of the session                |           Wiederaufnahme der Sitzungsperiode           |\n",
       "|     I declare resumed the session of the European      |      Ich erkläre die am Freitag, dem 17. Dezember      |\n",
       "|Parliament adjourned on Friday 17 December 1999, and I  |     unterbrochene Sitzungsperiode des Europäischen     |\n",
       "| would like once again to wish you a happy new year in  |     Parlaments für wiederaufgenommen, wünsche Ihnen    |\n",
       "| the hope that you enjoyed a pleasant festive period.   |  nochmals alles Gute zum Jahreswechsel und hoffe, daß  |\n",
       "|                                                        |                Sie schöne Ferien hatten.               |\n",
       "+-----------------------------------------------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">FULL Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "FULL Dataset: \u001b[1m(\u001b[0m\u001b[1;36m7000\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TRAIN Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5600</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "TRAIN Dataset: \u001b[1m(\u001b[0m\u001b[1;36m5600\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TEST Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1400</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "TEST Dataset: \u001b[1m(\u001b[0m\u001b[1;36m1400\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">[</span>Initiating Fine Tuning<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                              <a href=\"file:///tmp/ipykernel_27241/405145780.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">405145780.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_27241/405145780.py#75\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">75</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mInitiating Fine Tuning\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                                                              \u001b]8;id=529603;file:///tmp/ipykernel_27241/405145780.py\u001b\\\u001b[2m405145780.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=103545;file:///tmp/ipykernel_27241/405145780.py#75\u001b\\\u001b[2m75\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                                                                         \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                   | 0/4 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:01,  1.36s/it]\u001b[A\n",
      "2it [00:02,  1.17s/it]\u001b[A\n",
      "3it [00:03,  1.11s/it]\u001b[A\n",
      "4it [00:04,  1.08s/it]\u001b[A\n",
      "5it [00:05,  1.07s/it]\u001b[A\n",
      "6it [00:06,  1.06s/it]\u001b[A\n",
      "7it [00:07,  1.05s/it]\u001b[A\n",
      "8it [00:08,  1.05s/it]\u001b[A\n",
      "9it [00:09,  1.05s/it]\u001b[A\n",
      "10it [00:10,  1.05s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "11it [00:11,  1.05s/it]\u001b[A\n",
      "12it [00:12,  1.05s/it]\u001b[A\n",
      "13it [00:13,  1.05s/it]\u001b[A\n",
      "14it [00:14,  1.04s/it]\u001b[A\n",
      "15it [00:15,  1.04s/it]\u001b[A\n",
      "16it [00:17,  1.05s/it]\u001b[A\n",
      "17it [00:18,  1.04s/it]\u001b[A\n",
      "18it [00:19,  1.04s/it]\u001b[A\n",
      "19it [00:20,  1.04s/it]\u001b[A\n",
      "20it [00:21,  1.03s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "21it [00:22,  1.04s/it]\u001b[A\n",
      "22it [00:23,  1.03s/it]\u001b[A\n",
      "23it [00:24,  1.03s/it]\u001b[A\n",
      "24it [00:25,  1.04s/it]\u001b[A\n",
      "25it [00:26,  1.03s/it]\u001b[A\n",
      "26it [00:27,  1.04s/it]\u001b[A\n",
      "27it [00:28,  1.03s/it]\u001b[A\n",
      "28it [00:29,  1.03s/it]\u001b[A\n",
      "29it [00:30,  1.03s/it]\u001b[A\n",
      "30it [00:31,  1.03s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "31it [00:32,  1.04s/it]\u001b[A\n",
      "32it [00:33,  1.04s/it]\u001b[A\n",
      "33it [00:34,  1.04s/it]\u001b[A\n",
      "34it [00:35,  1.04s/it]\u001b[A\n",
      "35it [00:36,  1.04s/it]\u001b[A\n",
      "36it [00:37,  1.03s/it]\u001b[A\n",
      "37it [00:38,  1.03s/it]\u001b[A\n",
      "38it [00:39,  1.03s/it]\u001b[A\n",
      "39it [00:40,  1.03s/it]\u001b[A\n",
      "40it [00:41,  1.03s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "41it [00:42,  1.03s/it]\u001b[A\n",
      "42it [00:43,  1.03s/it]\u001b[A\n",
      "43it [00:44,  1.03s/it]\u001b[A\n",
      "44it [00:45,  1.04s/it]\u001b[A\n",
      "45it [00:47,  1.04s/it]\u001b[A\n",
      "46it [00:48,  1.04s/it]\u001b[A\n",
      "47it [00:49,  1.04s/it]\u001b[A\n",
      "48it [00:50,  1.03s/it]\u001b[A\n",
      "49it [00:51,  1.03s/it]\u001b[A\n",
      "50it [00:52,  1.03s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "51it [00:53,  1.04s/it]\u001b[A\n",
      "52it [00:54,  1.03s/it]\u001b[A\n",
      "53it [00:55,  1.03s/it]\u001b[A\n",
      "54it [00:56,  1.03s/it]\u001b[A\n",
      "55it [00:57,  1.03s/it]\u001b[A\n",
      "56it [00:58,  1.03s/it]\u001b[A\n",
      "57it [00:59,  1.03s/it]\u001b[A\n",
      "58it [01:00,  1.04s/it]\u001b[A\n",
      "59it [01:01,  1.04s/it]\u001b[A\n",
      "60it [01:02,  1.04s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "61it [01:03,  1.04s/it]\u001b[A\n",
      "62it [01:04,  1.04s/it]\u001b[A\n",
      "63it [01:05,  1.04s/it]\u001b[A\n",
      "64it [01:06,  1.05s/it]\u001b[A\n",
      "65it [01:07,  1.04s/it]\u001b[A\n",
      "66it [01:08,  1.04s/it]\u001b[A\n",
      "67it [01:09,  1.05s/it]\u001b[A\n",
      "68it [01:10,  1.05s/it]\u001b[A\n",
      "69it [01:11,  1.04s/it]\u001b[A\n",
      "70it [01:12,  1.04s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "71it [01:14,  1.05s/it]\u001b[A\n",
      "72it [01:15,  1.04s/it]\u001b[A\n",
      "73it [01:16,  1.05s/it]\u001b[A\n",
      "74it [01:17,  1.05s/it]\u001b[A\n",
      "75it [01:18,  1.05s/it]\u001b[A\n",
      "76it [01:19,  1.05s/it]\u001b[A\n",
      "77it [01:20,  1.05s/it]\u001b[A\n",
      "78it [01:21,  1.04s/it]\u001b[A\n",
      "79it [01:22,  1.04s/it]\u001b[A\n",
      "80it [01:23,  1.04s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "81it [01:24,  1.04s/it]\u001b[A\n",
      "82it [01:25,  1.04s/it]\u001b[A\n",
      "83it [01:26,  1.04s/it]\u001b[A\n",
      "84it [01:27,  1.04s/it]\u001b[A\n",
      "85it [01:28,  1.04s/it]\u001b[A\n",
      "86it [01:29,  1.04s/it]\u001b[A\n",
      "87it [01:30,  1.04s/it]\u001b[A\n",
      "88it [01:31,  1.04s/it]\u001b[A\n",
      " 25%|██████▊                    | 1/4 [01:31<04:34, 91.48s/it]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00,  1.14it/s]\u001b[A\n",
      "2it [00:01,  1.02it/s]\u001b[A\n",
      "3it [00:02,  1.01s/it]\u001b[A\n",
      "4it [00:03,  1.02s/it]\u001b[A\n",
      "5it [00:05,  1.02s/it]\u001b[A\n",
      "6it [00:06,  1.03s/it]\u001b[A\n",
      "7it [00:07,  1.03s/it]\u001b[A\n",
      "8it [00:08,  1.03s/it]\u001b[A\n",
      "9it [00:09,  1.03s/it]\u001b[A\n",
      "10it [00:10,  1.03s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "11it [00:11,  1.04s/it]\u001b[A\n",
      "12it [00:12,  1.04s/it]\u001b[A\n",
      "13it [00:13,  1.03s/it]\u001b[A\n",
      "14it [00:14,  1.03s/it]\u001b[A\n",
      "15it [00:15,  1.03s/it]\u001b[A\n",
      "16it [00:16,  1.02s/it]\u001b[A\n",
      "17it [00:17,  1.03s/it]\u001b[A\n",
      "18it [00:18,  1.03s/it]\u001b[A\n",
      "19it [00:19,  1.03s/it]\u001b[A\n",
      "20it [00:20,  1.03s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "21it [00:21,  1.05s/it]\u001b[A\n",
      "22it [00:22,  1.04s/it]\u001b[A\n",
      "23it [00:23,  1.04s/it]\u001b[A\n",
      "24it [00:24,  1.04s/it]\u001b[A\n",
      "25it [00:25,  1.04s/it]\u001b[A\n",
      "26it [00:26,  1.04s/it]\u001b[A\n",
      "27it [00:27,  1.04s/it]\u001b[A\n",
      "28it [00:28,  1.04s/it]\u001b[A\n",
      "29it [00:29,  1.05s/it]\u001b[A\n",
      "30it [00:30,  1.05s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "31it [00:32,  1.06s/it]\u001b[A\n",
      "32it [00:33,  1.05s/it]\u001b[A\n",
      "33it [00:34,  1.05s/it]\u001b[A\n",
      "34it [00:35,  1.05s/it]\u001b[A\n",
      "35it [00:36,  1.05s/it]\u001b[A\n",
      "36it [00:37,  1.05s/it]\u001b[A\n",
      "37it [00:38,  1.04s/it]\u001b[A\n",
      "38it [00:39,  1.04s/it]\u001b[A\n",
      "39it [00:40,  1.04s/it]\u001b[A\n",
      "40it [00:41,  1.04s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "41it [00:42,  1.04s/it]\u001b[A\n",
      "42it [00:43,  1.04s/it]\u001b[A\n",
      "43it [00:44,  1.03s/it]\u001b[A\n",
      "44it [00:45,  1.04s/it]\u001b[A\n",
      "45it [00:46,  1.04s/it]\u001b[A\n",
      "46it [00:47,  1.04s/it]\u001b[A\n",
      "47it [00:48,  1.04s/it]\u001b[A\n",
      "48it [00:49,  1.04s/it]\u001b[A\n",
      "49it [00:50,  1.04s/it]\u001b[A\n",
      "50it [00:51,  1.04s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "51it [00:52,  1.04s/it]\u001b[A\n",
      "52it [00:53,  1.04s/it]\u001b[A\n",
      "53it [00:54,  1.04s/it]\u001b[A\n",
      "54it [00:55,  1.04s/it]\u001b[A\n",
      "55it [00:57,  1.04s/it]\u001b[A\n",
      "56it [00:58,  1.04s/it]\u001b[A\n",
      "57it [00:59,  1.04s/it]\u001b[A\n",
      "58it [01:00,  1.03s/it]\u001b[A\n",
      "59it [01:01,  1.03s/it]\u001b[A\n",
      "60it [01:02,  1.04s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "61it [01:03,  1.05s/it]\u001b[A\n",
      "62it [01:04,  1.04s/it]\u001b[A\n",
      "63it [01:05,  1.03s/it]\u001b[A\n",
      "64it [01:06,  1.04s/it]\u001b[A\n",
      "65it [01:07,  1.04s/it]\u001b[A\n",
      "66it [01:08,  1.04s/it]\u001b[A\n",
      "67it [01:09,  1.04s/it]\u001b[A\n",
      "68it [01:10,  1.04s/it]\u001b[A\n",
      "69it [01:11,  1.03s/it]\u001b[A\n",
      "70it [01:12,  1.03s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "71it [01:13,  1.04s/it]\u001b[A\n",
      "72it [01:14,  1.04s/it]\u001b[A\n",
      "73it [01:15,  1.04s/it]\u001b[A\n",
      "74it [01:16,  1.03s/it]\u001b[A\n",
      "75it [01:17,  1.03s/it]\u001b[A\n",
      "76it [01:18,  1.04s/it]\u001b[A\n",
      "77it [01:19,  1.04s/it]\u001b[A\n",
      "78it [01:20,  1.04s/it]\u001b[A\n",
      "79it [01:21,  1.04s/it]\u001b[A\n",
      "80it [01:22,  1.03s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "81it [01:23,  1.04s/it]\u001b[A\n",
      "82it [01:24,  1.04s/it]\u001b[A\n",
      "83it [01:26,  1.04s/it]\u001b[A\n",
      "84it [01:27,  1.03s/it]\u001b[A\n",
      "85it [01:28,  1.04s/it]\u001b[A\n",
      "86it [01:29,  1.04s/it]\u001b[A\n",
      "87it [01:30,  1.04s/it]\u001b[A\n",
      "88it [01:30,  1.03s/it]\u001b[A\n",
      " 50%|█████████████▌             | 2/4 [03:02<03:02, 91.16s/it]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00,  1.17it/s]\u001b[A\n",
      "2it [00:01,  1.04it/s]\u001b[A\n",
      "3it [00:02,  1.00s/it]\u001b[A\n",
      "4it [00:03,  1.01s/it]\u001b[A\n",
      "5it [00:04,  1.01s/it]\u001b[A\n",
      "6it [00:06,  1.02s/it]\u001b[A\n",
      "7it [00:07,  1.03s/it]\u001b[A\n",
      "8it [00:08,  1.03s/it]\u001b[A\n",
      "9it [00:09,  1.04s/it]\u001b[A\n",
      "10it [00:10,  1.04s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "11it [00:11,  1.05s/it]\u001b[A\n",
      "12it [00:12,  1.05s/it]\u001b[A\n",
      "13it [00:13,  1.05s/it]\u001b[A\n",
      "14it [00:14,  1.04s/it]\u001b[A\n",
      "15it [00:15,  1.04s/it]\u001b[A\n",
      "16it [00:16,  1.04s/it]\u001b[A\n",
      "17it [00:17,  1.04s/it]\u001b[A\n",
      "18it [00:18,  1.05s/it]\u001b[A\n",
      "19it [00:19,  1.05s/it]\u001b[A\n",
      "20it [00:20,  1.05s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "21it [00:21,  1.05s/it]\u001b[A\n",
      "22it [00:22,  1.05s/it]\u001b[A\n",
      "23it [00:23,  1.04s/it]\u001b[A\n",
      "24it [00:24,  1.05s/it]\u001b[A\n",
      "25it [00:25,  1.05s/it]\u001b[A\n",
      "26it [00:26,  1.05s/it]\u001b[A\n",
      "27it [00:27,  1.04s/it]\u001b[A\n",
      "28it [00:29,  1.05s/it]\u001b[A\n",
      "29it [00:30,  1.04s/it]\u001b[A\n",
      "30it [00:31,  1.05s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(1.4371, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(1.4371, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "31it [00:32,  1.06s/it]\u001b[A\n",
      "32it [00:33,  1.05s/it]\u001b[A\n",
      "33it [00:34,  1.04s/it]\u001b[A\n",
      "34it [00:35,  1.04s/it]\u001b[A\n",
      "35it [00:36,  1.04s/it]\u001b[A\n",
      "36it [00:37,  1.04s/it]\u001b[A\n",
      "37it [00:38,  1.04s/it]\u001b[A\n",
      "38it [00:39,  1.04s/it]\u001b[A\n",
      "39it [00:40,  1.04s/it]\u001b[A\n",
      "40it [00:41,  1.04s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(1.4371, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.5288, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(1.4371, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.5288, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "41it [00:42,  1.04s/it]\u001b[A\n",
      "42it [00:43,  1.05s/it]\u001b[A\n",
      "43it [00:44,  1.04s/it]\u001b[A\n",
      "44it [00:45,  1.05s/it]\u001b[A\n",
      "45it [00:46,  1.04s/it]\u001b[A\n",
      "46it [00:47,  1.04s/it]\u001b[A\n",
      "47it [00:48,  1.04s/it]\u001b[A\n",
      "48it [00:49,  1.04s/it]\u001b[A\n",
      "49it [00:50,  1.05s/it]\u001b[A\n",
      "50it [00:51,  1.04s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(1.4371, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.5288, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(1.5549, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(1.4371, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.5288, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(1.5549, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "51it [00:53,  1.05s/it]\u001b[A\n",
      "52it [00:54,  1.05s/it]\u001b[A\n",
      "53it [00:55,  1.05s/it]\u001b[A\n",
      "54it [00:56,  1.04s/it]\u001b[A\n",
      "55it [00:57,  1.04s/it]\u001b[A\n",
      "56it [00:58,  1.05s/it]\u001b[A\n",
      "57it [00:59,  1.05s/it]\u001b[A\n",
      "58it [01:00,  1.05s/it]\u001b[A\n",
      "59it [01:01,  1.04s/it]\u001b[A\n",
      "60it [01:02,  1.04s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(1.4371, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.5288, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(1.5549, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5116, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(1.4371, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.5288, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(1.5549, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5116, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "61it [01:03,  1.05s/it]\u001b[A\n",
      "62it [01:04,  1.04s/it]\u001b[A\n",
      "63it [01:05,  1.04s/it]\u001b[A\n",
      "64it [01:06,  1.04s/it]\u001b[A\n",
      "65it [01:07,  1.04s/it]\u001b[A\n",
      "66it [01:08,  1.04s/it]\u001b[A\n",
      "67it [01:09,  1.04s/it]\u001b[A\n",
      "68it [01:10,  1.04s/it]\u001b[A\n",
      "69it [01:11,  1.04s/it]\u001b[A\n",
      "70it [01:12,  1.04s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(1.4371, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.5288, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(1.5549, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5116, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(1.3800, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(1.4371, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.5288, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(1.5549, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5116, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(1.3800, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "71it [01:13,  1.05s/it]\u001b[A\n",
      "72it [01:14,  1.05s/it]\u001b[A\n",
      "73it [01:15,  1.04s/it]\u001b[A\n",
      "74it [01:17,  1.04s/it]\u001b[A\n",
      "75it [01:18,  1.04s/it]\u001b[A\n",
      "76it [01:19,  1.04s/it]\u001b[A\n",
      "77it [01:20,  1.05s/it]\u001b[A\n",
      "78it [01:21,  1.04s/it]\u001b[A\n",
      "79it [01:22,  1.04s/it]\u001b[A\n",
      "80it [01:23,  1.04s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(1.4371, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.5288, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(1.5549, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5116, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(1.3800, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(1.5107, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(1.4371, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.5288, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(1.5549, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5116, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(1.3800, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(1.5107, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "81it [01:24,  1.05s/it]\u001b[A\n",
      "82it [01:25,  1.04s/it]\u001b[A\n",
      "83it [01:26,  1.04s/it]\u001b[A\n",
      "84it [01:27,  1.04s/it]\u001b[A\n",
      "85it [01:28,  1.04s/it]\u001b[A\n",
      "86it [01:29,  1.04s/it]\u001b[A\n",
      "87it [01:30,  1.04s/it]\u001b[A\n",
      "88it [01:31,  1.04s/it]\u001b[A\n",
      " 75%|████████████████████▎      | 3/4 [04:33<01:31, 91.23s/it]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(1.4371, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.5288, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(1.5549, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5116, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(1.3800, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(1.5107, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(1.4731, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(1.4371, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.5288, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(1.5549, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5116, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(1.3800, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(1.5107, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(1.4731, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00,  1.15it/s]\u001b[A\n",
      "2it [00:01,  1.03it/s]\u001b[A\n",
      "3it [00:02,  1.00it/s]\u001b[A\n",
      "4it [00:03,  1.01s/it]\u001b[A\n",
      "5it [00:05,  1.01s/it]\u001b[A\n",
      "6it [00:06,  1.02s/it]\u001b[A\n",
      "7it [00:07,  1.03s/it]\u001b[A\n",
      "8it [00:08,  1.03s/it]\u001b[A\n",
      "9it [00:09,  1.03s/it]\u001b[A\n",
      "10it [00:10,  1.03s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(1.4371, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.5288, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(1.5549, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5116, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(1.3800, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(1.5107, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(1.4731, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  10   | tensor(1.4112, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(1.4371, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.5288, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(1.5549, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5116, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(1.3800, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(1.5107, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(1.4731, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  10   | tensor(1.4112, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "11it [00:11,  1.04s/it]\u001b[A\n",
      "12it [00:12,  1.04s/it]\u001b[A\n",
      "13it [00:13,  1.04s/it]\u001b[A\n",
      "14it [00:14,  1.04s/it]\u001b[A\n",
      "15it [00:15,  1.03s/it]\u001b[A\n",
      "16it [00:16,  1.04s/it]\u001b[A\n",
      "17it [00:17,  1.04s/it]\u001b[A\n",
      "18it [00:18,  1.05s/it]\u001b[A\n",
      "19it [00:19,  1.04s/it]\u001b[A\n",
      "20it [00:20,  1.04s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(1.4371, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.5288, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(1.5549, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5116, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(1.3800, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(1.5107, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(1.4731, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  10   | tensor(1.4112, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  20   | tensor(1.5351, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(1.4371, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.5288, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(1.5549, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5116, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(1.3800, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(1.5107, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(1.4731, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  10   | tensor(1.4112, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  20   | tensor(1.5351, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "21it [00:21,  1.05s/it]\u001b[A\n",
      "22it [00:22,  1.04s/it]\u001b[A\n",
      "23it [00:23,  1.04s/it]\u001b[A\n",
      "24it [00:24,  1.04s/it]\u001b[A\n",
      "25it [00:25,  1.04s/it]\u001b[A\n",
      "26it [00:26,  1.05s/it]\u001b[A\n",
      "27it [00:27,  1.05s/it]\u001b[A\n",
      "28it [00:28,  1.04s/it]\u001b[A\n",
      "29it [00:30,  1.04s/it]\u001b[A\n",
      "30it [00:31,  1.04s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(1.4371, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.5288, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(1.5549, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5116, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(1.3800, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(1.5107, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(1.4731, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  10   | tensor(1.4112, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  20   | tensor(1.5351, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  30   | tensor(1.5777, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(1.4371, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.5288, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(1.5549, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5116, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(1.3800, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(1.5107, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(1.4731, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  10   | tensor(1.4112, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  20   | tensor(1.5351, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  30   | tensor(1.5777, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "31it [00:32,  1.05s/it]\u001b[A\n",
      "32it [00:33,  1.04s/it]\u001b[A\n",
      "33it [00:34,  1.04s/it]\u001b[A\n",
      "34it [00:35,  1.04s/it]\u001b[A\n",
      "35it [00:36,  1.04s/it]\u001b[A\n",
      "36it [00:37,  1.04s/it]\u001b[A\n",
      "37it [00:38,  1.04s/it]\u001b[A\n",
      "38it [00:39,  1.04s/it]\u001b[A\n",
      "39it [00:40,  1.04s/it]\u001b[A\n",
      "40it [00:41,  1.03s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(1.4371, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.5288, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(1.5549, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5116, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(1.3800, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(1.5107, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(1.4731, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  10   | tensor(1.4112, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  20   | tensor(1.5351, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  30   | tensor(1.5777, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  40   | tensor(1.5362, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(1.4371, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.5288, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(1.5549, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5116, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(1.3800, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(1.5107, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(1.4731, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  10   | tensor(1.4112, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  20   | tensor(1.5351, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  30   | tensor(1.5777, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  40   | tensor(1.5362, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "41it [00:42,  1.05s/it]\u001b[A\n",
      "42it [00:43,  1.04s/it]\u001b[A\n",
      "43it [00:44,  1.05s/it]\u001b[A\n",
      "44it [00:45,  1.04s/it]\u001b[A\n",
      "45it [00:46,  1.05s/it]\u001b[A\n",
      "46it [00:47,  1.04s/it]\u001b[A\n",
      "47it [00:48,  1.04s/it]\u001b[A\n",
      "48it [00:49,  1.04s/it]\u001b[A\n",
      "49it [00:50,  1.03s/it]\u001b[A\n",
      "50it [00:51,  1.04s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(1.4371, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.5288, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(1.5549, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5116, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(1.3800, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(1.5107, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(1.4731, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  10   | tensor(1.4112, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  20   | tensor(1.5351, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  30   | tensor(1.5777, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  40   | tensor(1.5362, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  50   | tensor(1.4875, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(1.4371, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.5288, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(1.5549, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5116, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(1.3800, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(1.5107, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(1.4731, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  10   | tensor(1.4112, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  20   | tensor(1.5351, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  30   | tensor(1.5777, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  40   | tensor(1.5362, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  50   | tensor(1.4875, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "51it [00:52,  1.05s/it]\u001b[A\n",
      "52it [00:53,  1.05s/it]\u001b[A\n",
      "53it [00:55,  1.05s/it]\u001b[A\n",
      "54it [00:56,  1.04s/it]\u001b[A\n",
      "55it [00:57,  1.06s/it]\u001b[A\n",
      "56it [00:58,  1.06s/it]\u001b[A\n",
      "57it [00:59,  1.05s/it]\u001b[A\n",
      "58it [01:00,  1.05s/it]\u001b[A\n",
      "59it [01:01,  1.05s/it]\u001b[A\n",
      "60it [01:02,  1.04s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(1.4371, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.5288, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(1.5549, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5116, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(1.3800, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(1.5107, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(1.4731, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  10   | tensor(1.4112, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  20   | tensor(1.5351, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  30   | tensor(1.5777, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  40   | tensor(1.5362, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  50   | tensor(1.4875, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  60   | tensor(1.4142, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(1.4371, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.5288, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(1.5549, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5116, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(1.3800, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(1.5107, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(1.4731, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  10   | tensor(1.4112, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  20   | tensor(1.5351, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  30   | tensor(1.5777, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  40   | tensor(1.5362, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  50   | tensor(1.4875, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  60   | tensor(1.4142, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "61it [01:03,  1.06s/it]\u001b[A\n",
      "62it [01:04,  1.06s/it]\u001b[A\n",
      "63it [01:05,  1.06s/it]\u001b[A\n",
      "64it [01:06,  1.06s/it]\u001b[A\n",
      "65it [01:07,  1.05s/it]\u001b[A\n",
      "66it [01:08,  1.05s/it]\u001b[A\n",
      "67it [01:09,  1.05s/it]\u001b[A\n",
      "68it [01:10,  1.05s/it]\u001b[A\n",
      "69it [01:11,  1.05s/it]\u001b[A\n",
      "70it [01:12,  1.05s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(1.4371, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.5288, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(1.5549, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5116, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(1.3800, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(1.5107, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(1.4731, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  10   | tensor(1.4112, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  20   | tensor(1.5351, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  30   | tensor(1.5777, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  40   | tensor(1.5362, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  50   | tensor(1.4875, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  60   | tensor(1.4142, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  70   | tensor(1.3832, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(1.4371, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.5288, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(1.5549, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5116, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(1.3800, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(1.5107, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(1.4731, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  10   | tensor(1.4112, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  20   | tensor(1.5351, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  30   | tensor(1.5777, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  40   | tensor(1.5362, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  50   | tensor(1.4875, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  60   | tensor(1.4142, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  70   | tensor(1.3832, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "71it [01:13,  1.06s/it]\u001b[A\n",
      "72it [01:15,  1.05s/it]\u001b[A\n",
      "73it [01:16,  1.05s/it]\u001b[A\n",
      "74it [01:17,  1.05s/it]\u001b[A\n",
      "75it [01:18,  1.05s/it]\u001b[A\n",
      "76it [01:19,  1.05s/it]\u001b[A\n",
      "77it [01:20,  1.05s/it]\u001b[A\n",
      "78it [01:21,  1.04s/it]\u001b[A\n",
      "79it [01:22,  1.04s/it]\u001b[A\n",
      "80it [01:23,  1.04s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(1.4371, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.5288, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(1.5549, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5116, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(1.3800, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(1.5107, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |   0   | tensor(1.4731, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  10   | tensor(1.4112, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  20   | tensor(1.5351, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  30   | tensor(1.5777, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  40   | tensor(1.5362, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  50   | tensor(1.4875, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  60   | tensor(1.4142, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  70   | tensor(1.3832, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  3   |  80   | tensor(1.6551, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(3.7981, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(2.2954, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.0425, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(1.8098, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(1.6799, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(1.6850, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(1.5852, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(1.7962, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.5763, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(1.5678, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(1.5788, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(1.4153, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(1.4966, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(1.5285, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(1.6680, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.5087, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.3622, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.3476, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.6144, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(1.4371, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.5288, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(1.5549, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5116, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(1.3800, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(1.5107, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |   0   | tensor(1.4731, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  10   | tensor(1.4112, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  20   | tensor(1.5351, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  30   | tensor(1.5777, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  40   | tensor(1.5362, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  50   | tensor(1.4875, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  60   | tensor(1.4142, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  70   | tensor(1.3832, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  3   |  80   | tensor(1.6551, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "81it [01:24,  1.05s/it]\u001b[A\n",
      "82it [01:25,  1.04s/it]\u001b[A\n",
      "83it [01:26,  1.04s/it]\u001b[A\n",
      "84it [01:27,  1.04s/it]\u001b[A\n",
      "85it [01:28,  1.04s/it]\u001b[A\n",
      "86it [01:29,  1.04s/it]\u001b[A\n",
      "87it [01:30,  1.04s/it]\u001b[A\n",
      "88it [01:31,  1.04s/it]\u001b[A\n",
      "100%|███████████████████████████| 4/4 [06:05<00:00, 91.29s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[07:37:26] </span><span style=\"font-weight: bold\">[</span>Saving Model<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                        <a href=\"file:///tmp/ipykernel_27241/405145780.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">405145780.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_27241/405145780.py#80\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">80</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[07:37:26]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mSaving Model\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                                                                        \u001b]8;id=612559;file:///tmp/ipykernel_27241/405145780.py\u001b\\\u001b[2m405145780.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=453259;file:///tmp/ipykernel_27241/405145780.py#80\u001b\\\u001b[2m80\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                                                                         \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[07:37:27] </span><span style=\"font-weight: bold\">[</span>Initiating Validation<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                               <a href=\"file:///tmp/ipykernel_27241/405145780.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">405145780.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_27241/405145780.py#88\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">88</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[07:37:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mInitiating Validation\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                                                               \u001b]8;id=61807;file:///tmp/ipykernel_27241/405145780.py\u001b\\\u001b[2m405145780.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=988790;file:///tmp/ipykernel_27241/405145780.py#88\u001b\\\u001b[2m88\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                                                                         \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                   | 0/5 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:15, 15.55s/it]\u001b[A\n",
      "2it [00:32, 16.45s/it]\u001b[A\n",
      "3it [00:48, 15.96s/it]\u001b[A\n",
      "4it [01:04, 16.20s/it]\u001b[A\n",
      "5it [01:19, 15.90s/it]\u001b[A\n",
      "6it [01:39, 17.12s/it]\u001b[A\n",
      "7it [01:54, 16.51s/it]\u001b[A\n",
      "8it [02:10, 16.29s/it]\u001b[A\n",
      "9it [02:24, 15.51s/it]\u001b[A\n",
      "10it [02:40, 15.74s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m10\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "11it [02:56, 15.80s/it]\u001b[A\n",
      "12it [03:11, 15.71s/it]\u001b[A\n",
      "13it [03:29, 16.13s/it]\u001b[A\n",
      "14it [03:46, 16.38s/it]\u001b[A\n",
      "15it [04:02, 16.53s/it]\u001b[A\n",
      "16it [04:19, 16.50s/it]\u001b[A\n",
      "17it [04:35, 16.53s/it]\u001b[A\n",
      "18it [04:51, 16.33s/it]\u001b[A\n",
      "19it [05:08, 16.50s/it]\u001b[A\n",
      "20it [05:23, 16.02s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m20\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "21it [05:40, 16.27s/it]\u001b[A\n",
      "22it [05:54, 16.12s/it]\u001b[A\n",
      " 20%|█████▏                    | 1/5 [05:54<23:39, 354.77s/it]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:15, 15.26s/it]\u001b[A\n",
      "2it [00:32, 16.36s/it]\u001b[A\n",
      "3it [00:47, 15.99s/it]\u001b[A\n",
      "4it [01:04, 16.28s/it]\u001b[A\n",
      "5it [01:20, 15.96s/it]\u001b[A\n",
      "6it [01:39, 17.14s/it]\u001b[A\n",
      "7it [01:54, 16.49s/it]\u001b[A\n",
      "8it [02:10, 16.27s/it]\u001b[A\n",
      "9it [02:24, 15.52s/it]\u001b[A\n",
      "10it [02:40, 15.77s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m10\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "11it [02:56, 15.85s/it]\u001b[A\n",
      "12it [03:12, 15.74s/it]\u001b[A\n",
      "13it [03:29, 16.11s/it]\u001b[A\n",
      "14it [03:46, 16.34s/it]\u001b[A\n",
      "15it [04:02, 16.50s/it]\u001b[A\n",
      "16it [04:19, 16.44s/it]\u001b[A\n",
      "17it [04:35, 16.46s/it]\u001b[A\n",
      "18it [04:51, 16.33s/it]\u001b[A\n",
      "19it [05:08, 16.48s/it]\u001b[A\n",
      "20it [05:23, 16.00s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m20\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "21it [05:40, 16.23s/it]\u001b[A\n",
      "22it [05:54, 16.11s/it]\u001b[A\n",
      " 40%|██████████▍               | 2/5 [11:49<17:43, 354.65s/it]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:15, 15.36s/it]\u001b[A\n",
      "2it [00:32, 16.54s/it]\u001b[A\n",
      "3it [00:48, 16.01s/it]\u001b[A\n",
      "4it [01:04, 16.35s/it]\u001b[A\n",
      "5it [01:20, 16.05s/it]\u001b[A\n",
      "6it [01:40, 17.30s/it]\u001b[A\n",
      "7it [01:55, 16.63s/it]\u001b[A\n",
      "8it [02:11, 16.40s/it]\u001b[A\n",
      "9it [02:25, 15.60s/it]\u001b[A\n",
      "10it [02:41, 15.83s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m10\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "11it [02:57, 15.82s/it]\u001b[A\n",
      "12it [03:12, 15.72s/it]\u001b[A\n",
      "13it [03:29, 16.11s/it]\u001b[A\n",
      "14it [03:46, 16.35s/it]\u001b[A\n",
      "15it [04:03, 16.53s/it]\u001b[A\n",
      "16it [04:20, 16.51s/it]\u001b[A\n",
      "17it [04:36, 16.56s/it]\u001b[A\n",
      "18it [04:53, 16.45s/it]\u001b[A\n",
      "19it [05:09, 16.50s/it]\u001b[A\n",
      "20it [05:24, 16.02s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m20\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "21it [05:41, 16.22s/it]\u001b[A\n",
      "22it [05:55, 16.16s/it]\u001b[A\n",
      " 60%|███████████████▌          | 3/5 [17:44<11:50, 355.06s/it]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:15, 15.40s/it]\u001b[A\n",
      "2it [00:32, 16.53s/it]\u001b[A\n",
      "3it [00:48, 16.04s/it]\u001b[A\n",
      "4it [01:04, 16.31s/it]\u001b[A\n",
      "5it [01:20, 15.94s/it]\u001b[A\n",
      "6it [01:39, 17.05s/it]\u001b[A\n",
      "7it [01:54, 16.36s/it]\u001b[A\n",
      "8it [02:09, 16.13s/it]\u001b[A\n",
      "9it [02:23, 15.39s/it]\u001b[A\n",
      "10it [02:40, 15.66s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m10\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "11it [02:55, 15.69s/it]\u001b[A\n",
      "12it [03:10, 15.50s/it]\u001b[A\n",
      "13it [03:27, 15.96s/it]\u001b[A\n",
      "14it [03:44, 16.19s/it]\u001b[A\n",
      "15it [04:00, 16.24s/it]\u001b[A\n",
      "16it [04:16, 16.18s/it]\u001b[A\n",
      "17it [04:33, 16.22s/it]\u001b[A\n",
      "18it [04:49, 16.13s/it]\u001b[A\n",
      "19it [05:05, 16.28s/it]\u001b[A\n",
      "20it [05:20, 15.79s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m20\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "21it [05:37, 16.04s/it]\u001b[A\n",
      "22it [05:51, 15.97s/it]\u001b[A\n",
      " 80%|████████████████████▊     | 4/5 [23:36<05:53, 353.59s/it]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:15, 15.03s/it]\u001b[A\n",
      "2it [00:32, 16.35s/it]\u001b[A\n",
      "3it [00:47, 15.87s/it]\u001b[A\n",
      "4it [01:04, 16.18s/it]\u001b[A\n",
      "5it [01:19, 15.75s/it]\u001b[A\n",
      "6it [01:38, 16.96s/it]\u001b[A\n",
      "7it [01:53, 16.29s/it]\u001b[A\n",
      "8it [02:08, 16.00s/it]\u001b[A\n",
      "9it [02:22, 15.31s/it]\u001b[A\n",
      "10it [02:38, 15.60s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m10\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "11it [02:54, 15.62s/it]\u001b[A\n",
      "12it [03:09, 15.51s/it]\u001b[A\n",
      "13it [03:26, 15.89s/it]\u001b[A\n",
      "14it [03:43, 16.13s/it]\u001b[A\n",
      "15it [03:59, 16.27s/it]\u001b[A\n",
      "16it [04:15, 16.17s/it]\u001b[A\n",
      "17it [04:32, 16.26s/it]\u001b[A\n",
      "18it [04:48, 16.15s/it]\u001b[A\n",
      "19it [05:04, 16.30s/it]\u001b[A\n",
      "20it [05:19, 15.77s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m20\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "21it [05:35, 16.04s/it]\u001b[A\n",
      "22it [05:50, 15.91s/it]\u001b[A\n",
      "100%|██████████████████████████| 5/5 [29:26<00:00, 353.27s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[08:06:53] </span><span style=\"font-weight: bold\">[</span>Validation Completed.<span style=\"font-weight: bold\">]</span>                                                                  <a href=\"file:///tmp/ipykernel_27241/405145780.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">405145780.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_27241/405145780.py#96\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">96</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[08:06:53]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mValidation Completed.\u001b[1m]\u001b[0m                                                                  \u001b]8;id=132327;file:///tmp/ipykernel_27241/405145780.py\u001b\\\u001b[2m405145780.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=545168;file:///tmp/ipykernel_27241/405145780.py#96\u001b\\\u001b[2m96\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                                                                         \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Model<span style=\"font-weight: bold\">]</span> Model saved @ .<span style=\"color: #800080; text-decoration-color: #800080\">/FAMNet/HoSoTAs/en-de-new/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">model_files</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mModel\u001b[1m]\u001b[0m Model saved @ .\u001b[35m/FAMNet/HoSoTAs/en-de-new/\u001b[0m\u001b[95mmodel_files\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Validation<span style=\"font-weight: bold\">]</span> Generation on Validation data saved @ .<span style=\"color: #800080; text-decoration-color: #800080\">/FAMNet/HoSoTAs/en-de-new/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">predictions.csv</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mValidation\u001b[1m]\u001b[0m Generation on Validation data saved @ .\u001b[35m/FAMNet/HoSoTAs/en-de-new/\u001b[0m\u001b[95mpredictions.csv\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Logs<span style=\"font-weight: bold\">]</span> Logs saved @ .<span style=\"color: #800080; text-decoration-color: #800080\">/FAMNet/HoSoTAs/en-de-new/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">logs.txt</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mLogs\u001b[1m]\u001b[0m Logs saved @ .\u001b[35m/FAMNet/HoSoTAs/en-de-new/\u001b[0m\u001b[95mlogs.txt\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Wiederaufnahme der Sitzungsperiode'}]\n"
     ]
    }
   ],
   "source": [
    "T5Trainer(dataframe=df, \n",
    "          source_text=\"source_text\", \n",
    "          target_text=\"target_text\", \n",
    "          model_params=model_params, \n",
    "          output_dir=\"./FAMNet/HoSoTAs/en-de-new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=\"./FAMNet/HoSoTAs/en-de-new\"\n",
    "path = os.path.join(output_dir, \"model_files\")\n",
    "trained_tokenizer = T5Tokenizer.from_pretrained(path)\n",
    "trained_model = T5ForConditionalGeneration.from_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27241/476523010.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Resumption of the session'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtext1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_tokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrained_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_27241/2275239499.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(trained_model, trained_tokenizer, text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     generator = pipeline(\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0;34m\"text2text-generation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrained_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"device\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpipeline_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/pipelines/text2text_generation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         self.check_model_type(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, tokenizer, feature_extractor, image_processor, modelcard, framework, task, args_parser, device, torch_dtype, binary_output, **kwargs)\u001b[0m\n\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1809\u001b[0m             )\n\u001b[1;32m   1810\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1811\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    985\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    986\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 987\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "text = 'Resumption of the session'\n",
    "text1 = 'I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.'\n",
    "inference(trained_model=trained_model, trained_tokenizer=trained_tokenizer, text=text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen \n",
    "# Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, \n",
    "# daß Sie schöne Ferien hatten.\n",
    "\n",
    "# BLEU score\n",
    "# from nltk.translate.bleu_score import sentence_bleu\n",
    "def compute_bleu(y_pred, y_true):\n",
    "    metric = load_metric('bleu')\n",
    "    metric.add_batch(predictions=y_pred, references=y_true)\n",
    "    report = metric.compute()\n",
    "    bleu = report['bleu'] * 100\n",
    "    return bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(loader, model, tokenizer, device):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for i, batch in enumerate(loader):\n",
    "\n",
    "        # Prepare and tokenize the source sentences\n",
    "        src_sentences = [prefix + line for line in batch[args().src_language]]\n",
    "        encoded_input = tokenizer(src_sentences, max_length=128,\n",
    "                                  padding=True, truncation=True,\n",
    "                                  return_tensors='pt', add_special_tokens=True).input_ids.to(device)\n",
    "\n",
    "        # Translate and decode the inputs\n",
    "        outputs = model.generate(encoded_input, max_length=175)\n",
    "        batch_pred = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "        # Concatenate the translated and reference sentences\n",
    "        for sentence in batch[args().tgt_language]:\n",
    "            sentence = tokenizer.tokenize(sentence)\n",
    "            # print(sentence)\n",
    "            y_true.append([sentence])\n",
    "        for sentence in batch_pred:\n",
    "            sentence = tokenizer.tokenize(sentence)\n",
    "            # print(sentence)\n",
    "            y_pred.append(sentence)\n",
    "\n",
    "    bleu = compute_bleu(y_pred, y_true)\n",
    "    print('Bleu Score: {:.2f}'.format(bleu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 25 08:06:57 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.106.00   Driver Version: 460.106.00   CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:06.0 Off |                    0 |\r\n",
      "| N/A   55C    P0    45W / 250W |  10282MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A     25624      C   ...t135/anaconda3/bin/python      977MiB |\r\n",
      "|    0   N/A  N/A     26332      C   ...t135/anaconda3/bin/python     1109MiB |\r\n",
      "|    0   N/A  N/A     26768      C   ...t135/anaconda3/bin/python      943MiB |\r\n",
      "|    0   N/A  N/A     27241      C   ...t135/anaconda3/bin/python     7251MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 25 08:06:58 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.106.00   Driver Version: 460.106.00   CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:06.0 Off |                    0 |\r\n",
      "| N/A   55C    P0    45W / 250W |   4156MiB / 16280MiB |     46%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A     25624      C   ...t135/anaconda3/bin/python      977MiB |\r\n",
      "|    0   N/A  N/A     26332      C   ...t135/anaconda3/bin/python     1109MiB |\r\n",
      "|    0   N/A  N/A     26768      C   ...t135/anaconda3/bin/python      943MiB |\r\n",
      "|    0   N/A  N/A     27241      C   ...t135/anaconda3/bin/python     1125MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
