{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a476b70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>origin_txt</th>\n",
       "      <th>w_task_set</th>\n",
       "      <th>output_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Translate 'Wiederaufnahme der Sitzungsperiode'...</td>\n",
       "      <td>Wiederaufnahme der Sitzungsperiode</td>\n",
       "      <td>translate_de_en</td>\n",
       "      <td>Resumption of the session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Translate 'Ich erkläre die am Freitag, dem 17....</td>\n",
       "      <td>Ich erkläre die am Freitag, dem 17. Dezember u...</td>\n",
       "      <td>translate_de_en</td>\n",
       "      <td>I declare resumed the session of the European ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Translate 'Wie Sie feststellen konnten, ist de...</td>\n",
       "      <td>Wie Sie feststellen konnten, ist der gefürchte...</td>\n",
       "      <td>translate_de_en</td>\n",
       "      <td>Although, as you will have seen, the dreaded '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Translate 'Im Parlament besteht der Wunsch nac...</td>\n",
       "      <td>Im Parlament besteht der Wunsch nach einer Aus...</td>\n",
       "      <td>translate_de_en</td>\n",
       "      <td>You have requested a debate on this subject in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Translate 'Heute möchte ich Sie bitten - das i...</td>\n",
       "      <td>Heute möchte ich Sie bitten - das ist auch der...</td>\n",
       "      <td>translate_de_en</td>\n",
       "      <td>In the meantime, I should like to observe a mi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text  \\\n",
       "0  Translate 'Wiederaufnahme der Sitzungsperiode'...   \n",
       "1  Translate 'Ich erkläre die am Freitag, dem 17....   \n",
       "2  Translate 'Wie Sie feststellen konnten, ist de...   \n",
       "3  Translate 'Im Parlament besteht der Wunsch nac...   \n",
       "4  Translate 'Heute möchte ich Sie bitten - das i...   \n",
       "\n",
       "                                          origin_txt       w_task_set  \\\n",
       "0                 Wiederaufnahme der Sitzungsperiode  translate_de_en   \n",
       "1  Ich erkläre die am Freitag, dem 17. Dezember u...  translate_de_en   \n",
       "2  Wie Sie feststellen konnten, ist der gefürchte...  translate_de_en   \n",
       "3  Im Parlament besteht der Wunsch nach einer Aus...  translate_de_en   \n",
       "4  Heute möchte ich Sie bitten - das ist auch der...  translate_de_en   \n",
       "\n",
       "                                          output_txt  \n",
       "0                          Resumption of the session  \n",
       "1  I declare resumed the session of the European ...  \n",
       "2  Although, as you will have seen, the dreaded '...  \n",
       "3  You have requested a debate on this subject in...  \n",
       "4  In the meantime, I should like to observe a mi...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from simpletransformers.t5 import T5Model\n",
    "from datasets import load_dataset, DownloadMode, load_metric\n",
    "from transformers import T5Tokenizer\n",
    "\n",
    "translate_template_de_en = lambda x:  \"Translate '%s' from english to german\"%x\n",
    "\n",
    "# train_df = load_dataset(\"wmt16\", \"de-en\", split=\"train[:100000]\", num_proc=8)\n",
    "df = pd.read_csv('task.csv')\n",
    "\n",
    "# Create data frame\n",
    "# df = pd.DataFrame({\n",
    "#     \"input_text\":[translate_template_de_en(train_df[i]['translation']['en']) for i in tqdm(range(len(train_df))) ],\n",
    "#     \"target_text\":[train_df[i]['translation']['en'] for i in tqdm(range(len(train_df))) ],\n",
    "#     \"prefix\":np.array([\"mx_model_selector\"]*len(train_df))\n",
    "# }).applymap(str)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79daa666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>prefix</th>\n",
       "      <th>output_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35514</th>\n",
       "      <td>Which English Lord led the Charge of the Light...</td>\n",
       "      <td>Which English Lord led the Charge of the Light...</td>\n",
       "      <td>TriviaQA</td>\n",
       "      <td>{'aliases': ['Earl of cardigan', 'Earls of Car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29757</th>\n",
       "      <td>Who wrote the song Momma Told Me Not To Come?</td>\n",
       "      <td>Who wrote the song Momma Told Me Not To Come?</td>\n",
       "      <td>TriviaQA</td>\n",
       "      <td>{'aliases': ['Randy Numan', 'Randy newman', 'R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33686</th>\n",
       "      <td>Who is most commonly attributed as finding Ame...</td>\n",
       "      <td>Who is most commonly attributed as finding Ame...</td>\n",
       "      <td>TriviaQA</td>\n",
       "      <td>{'aliases': ['Christoffa Corombo', 'Christophe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11171</th>\n",
       "      <td>Translate 'I often have the impression, unlike...</td>\n",
       "      <td>I often have the impression, unlike the countr...</td>\n",
       "      <td>translate_en_de</td>\n",
       "      <td>Ich habe manchmal den Eindruck, im Gegensatz z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24898</th>\n",
       "      <td>True or False: is al(oh)3 a strong base</td>\n",
       "      <td>is al(oh)3 a strong base</td>\n",
       "      <td>BoolQ</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              input_text  \\\n",
       "35514  Which English Lord led the Charge of the Light...   \n",
       "29757      Who wrote the song Momma Told Me Not To Come?   \n",
       "33686  Who is most commonly attributed as finding Ame...   \n",
       "11171  Translate 'I often have the impression, unlike...   \n",
       "24898            True or False: is al(oh)3 a strong base   \n",
       "\n",
       "                                             target_text           prefix  \\\n",
       "35514  Which English Lord led the Charge of the Light...         TriviaQA   \n",
       "29757      Who wrote the song Momma Told Me Not To Come?         TriviaQA   \n",
       "33686  Who is most commonly attributed as finding Ame...         TriviaQA   \n",
       "11171  I often have the impression, unlike the countr...  translate_en_de   \n",
       "24898                           is al(oh)3 a strong base            BoolQ   \n",
       "\n",
       "                                              output_txt  \n",
       "35514  {'aliases': ['Earl of cardigan', 'Earls of Car...  \n",
       "29757  {'aliases': ['Randy Numan', 'Randy newman', 'R...  \n",
       "33686  {'aliases': ['Christoffa Corombo', 'Christophe...  \n",
       "11171  Ich habe manchmal den Eindruck, im Gegensatz z...  \n",
       "24898                                              False  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename({'w_task_set':'prefix','origin_txt':'target_text'}, inplace=True, axis=1)\n",
    "df=df.sample(frac=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7e694c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Translate 'Wiederaufnahme der Sitzungsperiode' from german to english\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['input_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbd11b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agupt135/anaconda3/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce528f740dd4bcb938aae1315f73a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47978 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agupt135/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3712: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
      "\n",
      "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
      "this:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "labels = tokenizer(text_target=tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n",
      "/home/agupt135/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3586: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0e9f90b17244fc85a079d0bc3fe8ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2cqsahe3) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1690340cbbe849ba82cb5470cfba7782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>██▂▁▂▁▁▁▁▁</td></tr><tr><td>global_step</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>lr</td><td>▁▂▃▄▅▆▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.00711</td></tr><tr><td>global_step</td><td>500</td></tr><tr><td>lr</td><td>0.001</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">warm-durian-9</strong> at: <a href='https://wandb.ai/ankitgupta-nitp/Translation%20BART/runs/2cqsahe3' target=\"_blank\">https://wandb.ai/ankitgupta-nitp/Translation%20BART/runs/2cqsahe3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230325_041138-2cqsahe3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2cqsahe3). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9608978920b449939999d45401656080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669468349815968, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/agupt135/wandb/run-20230325_042450-55bbobl8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ankitgupta-nitp/T5-BART/runs/55bbobl8' target=\"_blank\">breezy-sky-1</a></strong> to <a href='https://wandb.ai/ankitgupta-nitp/T5-BART' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ankitgupta-nitp/T5-BART' target=\"_blank\">https://wandb.ai/ankitgupta-nitp/T5-BART</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ankitgupta-nitp/T5-BART/runs/55bbobl8' target=\"_blank\">https://wandb.ai/ankitgupta-nitp/T5-BART/runs/55bbobl8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3263ceb4befd45dd994160835073a869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 4:   0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d94a63d16ad4c6f96f73c0ffc084056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 4:   0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf9f72c1d1774231ab9595fc61bfc2e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 4:   0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "861d7ff01b1c4cd184f82e8830003ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 4:   0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3000, 0.01995186731851815)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/agupt135/anaconda3/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/home/agupt135/anaconda3/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 12] Cannot allocate memory\n",
      "Call stack:\n",
      "  File \"/home/agupt135/anaconda3/lib/python3.9/threading.py\", line 937, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/home/agupt135/anaconda3/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/agupt135/anaconda3/lib/python3.9/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
      "    self._run()\n",
      "  File \"/home/agupt135/anaconda3/lib/python3.9/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n",
      "    self._process(record)\n",
      "  File \"/home/agupt135/anaconda3/lib/python3.9/site-packages/wandb/sdk/internal/internal.py\", line 280, in _process\n",
      "    self._hm.handle(record)\n",
      "  File \"/home/agupt135/anaconda3/lib/python3.9/site-packages/wandb/sdk/internal/handler.py\", line 136, in handle\n",
      "    handler(record)\n",
      "  File \"/home/agupt135/anaconda3/lib/python3.9/site-packages/wandb/sdk/internal/handler.py\", line 144, in handle_request\n",
      "    logger.debug(f\"handle_request: {request_type}\")\n",
      "Message: 'handle_request: status_report'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/agupt135/anaconda3/lib/python3.9/logging/__init__.py\", line 1087, in emit\n",
      "    self.flush()\n",
      "  File \"/home/agupt135/anaconda3/lib/python3.9/logging/__init__.py\", line 1067, in flush\n",
      "    self.stream.flush()\n",
      "OSError: [Errno 12] Cannot allocate memory\n",
      "Call stack:\n",
      "  File \"/home/agupt135/anaconda3/lib/python3.9/threading.py\", line 937, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/home/agupt135/anaconda3/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/agupt135/anaconda3/lib/python3.9/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n",
      "    self._run()\n",
      "  File \"/home/agupt135/anaconda3/lib/python3.9/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n",
      "    self._process(record)\n",
      "  File \"/home/agupt135/anaconda3/lib/python3.9/site-packages/wandb/sdk/internal/internal.py\", line 280, in _process\n",
      "    self._hm.handle(record)\n",
      "  File \"/home/agupt135/anaconda3/lib/python3.9/site-packages/wandb/sdk/internal/handler.py\", line 136, in handle\n",
      "    handler(record)\n",
      "  File \"/home/agupt135/anaconda3/lib/python3.9/site-packages/wandb/sdk/internal/handler.py\", line 144, in handle_request\n",
      "    logger.debug(f\"handle_request: {request_type}\")\n",
      "Message: 'handle_request: status_report'\n",
      "Arguments: ()\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "model_args = {\n",
    "    \"reprocess_input_data\": True,\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"max_seq_length\": 128,\n",
    "    \"train_batch_size\": 64,\n",
    "    \"num_train_epochs\": 4,\n",
    "    \"save_eval_checkpoints\": True,\n",
    "    \"save_steps\": -1,\n",
    "    \"use_multiprocessing\": False,\n",
    "    \"fp16\": True,\n",
    "    \"wandb_project\": \"T5-BART\",\n",
    "}\n",
    "\n",
    "model = T5Model(\"t5\", \"t5-small\", args=model_args)\n",
    "torch.cuda.empty_cache()\n",
    "model.train_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abe27c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "976a1dda176b421091db42e0ffe097fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating outputs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55fe03f332414659858592c2f8837796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Decoding outputs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wiederaufnahme der Sitzungsperiode']\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([\"Translate 'Wiederaufnahme der Sitzungsperiode' from german to english\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b933f88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "import os\n",
    "\n",
    "output_dir=\"./T5toBART/\"\n",
    "path_model = os.path.join(output_dir, \"model\")\n",
    "path_args = os.path.join(output_dir, \"model_files\")\n",
    "model.save_model(path_model)\n",
    "model.save_model_args(path_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964bda38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
